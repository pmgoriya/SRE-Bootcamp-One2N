## Deployment steps

- Create minikube cluster with 3 nodes and label them as per the milestone
`minikube start --nodes=3 -p one2n`
`kubectl label node one2n type=application ;
kubectl label node one2n-m02 type=database ;
kubectl label node one2n-m03 type=dependent_services`

- Install helm
- deploy vault and eso on the node mentioned with their respective ns using node affinity, using helm
`helm install vault hashicorp/vault --version 0.30.0 --namespace vault --create-namespace --set server.dataStorage.storageClass=csi-hostpath-sc --set server.securityContext.runAsUser=100 --set server.securityContext.fsGroup=100 --set "server.nodeSelector.type=dependent_services" --set server.dataStorage.size=100Mi`

`helm install external-secrets external-secrets/external-secrets   --namespace external-secrets   --create-namespace   --set installCRDs=true   --set "nodeSelector.type=dependent_services"`

* Note
* In Minikube, the default `minikube-hostpath` storage class doesn't support proper permission handling (`fsGroup`, etc.).
* This causes Vault to fail writing to `/vault/data`, even with root or init containers.
* `csi-hostpath-sc` is a CSI-compliant storage class that supports Kubernetes security contexts.
* Enable it using: `minikube addons enable csi-hostpath-driver -p <profile-name>`.
* Use it with Helm via: `--set server.dataStorage.storageClass=csi-hostpath-sc`.
* Also the default csi sc's config for WaitForFirstConsumer cannot be changed: solves the error: vault cant start until pvc is bound and pod cant be scheduled until pvc is bound.
To solve this problem we need to provision another storage class using the command

`kubectl apply -f - <<EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: csi-hostpath-wffc
provisioner: hostpath.csi.k8s.io
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
EOF`


- Now unless and until the helm deployment arent ready, please wait

* OR simply exec into the vault `kubectl exec -it vault-0 -n vault -- /bin/sh` and do `vault operator init` unseal it using `vault operator unseal <unseal-key-1>` with upto 3 keys. Now the pods will be ready (Earlier it was only running)
* Now lets login to the vault `vault login <root-token>`
* Lets enable the path `vault secrets enable -path=secret kv`
* Now create the creds using the below cmd `vault kv put secret/database/creds DB_USER=<user> POSTGRES_USER=<user> DB_PASSWORD=<pwd> POSTGRES_PASSWORD=<pwd>`, both the password & username should be the same
* `vault token create`
* Use the token generated by the vault to be used in the secretstore, by creating a native kubernetes secret
`kubectl create secret generic vault-token \
--from-literal=token=<token> \
-n student-api`


- Create namespace `kubectl create ns student-api`
- Create ConfigMap for non-sensitive values (DB_HOST, DB_PORT,DB_NAME) already created through database.yml
- Create a secret store which tells the eso which backend to pick up the secrets from. `kubectl apply -f secretstore-vault.yml`
- Create external secret to map to exact resource `kubectl apply -f external-secret.yml`
- Create db `kubectl apply -f database.yml`
- Create api `kubectl apply -f application.yml`

- To check using the postman collection, find the port using `kubectl get svc api -n student-api`
- To get the minikube IP: `minikube ip -p one2n`